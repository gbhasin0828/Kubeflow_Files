# -*- coding: utf-8 -*-
"""KubeFlow_Model_For_Pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19_0dWxpGnnSyPMuxnk1bn8u74vZiKQBN
"""

!pip install kfp --upgrade

import kfp.components as compile
import kfp.dsl as dsl

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import os
from sklearn.linear_model import ElasticNet, LogisticRegression

def download_dataset(url: str, output_path: str) -> pd.DataFrame:
    import pandas as pd
    import os

    # Create the directory if it doesn't exist
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    # Download the dataset
    dataset = pd.read_csv(url)

    # Save the dataset locally
    dataset.to_csv(output_path, index=False)
    print(f"Data saved at {output_path}")

    # Return the DataFrame
    return dataset

def preprocess_dataset(df: pd.DataFrame):
  import pandas as pd
  df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']
  return df

def train_test_split(df: pd.DataFrame, output_dir : str) -> dict:
  import pandas as pd
  import numpy as np
  from sklearn.model_selection import train_test_split
  import os

  os.makedirs(output_dir, exist_ok = True)

  target_column = 'class'

  X = df.loc[:, df.columns != target_column]
  y = df.loc[:, df.columns == target_column]

  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=47)

  X_train_path = f'{output_dir}/X_train.npy'
  X_test_path = f'{output_dir}/X_test.npy'
  y_train_path = f'{output_dir}/y_train.npy'
  y_test_path = f'{output_dir}/y_test.npy'

  np.save(X_train_path, X_train)
  np.save(X_test_path, X_test)
  np.save(y_train_path, y_train)
  np.save(y_test_path, y_test)

  return {
      "X_train" : X_train_path,
      "X_test" : X_test_path,
      "y_train" : y_train_path,
      "y_test" : y_test_path
  }

def train_model(path : dict, model_output_path):
  import numpy as np
  import pickle
  from sklearn.linear_model import LogisticRegression
  import os

  X_train = np.load(path['X_train'], allow_pickle = True)
  y_train = np.load(path['y_train'], allow_pickle = True)

  classifier = LogisticRegression(max_iter=500)
  classifier.fit(X_train, y_train)

  os.makedirs(os.path.dirname(model_output_path), exist_ok = True)
  with open(model_output_path, 'wb') as f:
    pickle.dump(classifier, f)
  print("Model Training Completed")

if __name__ == '__main__':

  dataset_url = 'https://raw.githubusercontent.com/gbhasin0828/Kubeflow_Files/main/iris.csv'

  output_path = 'data/final_df.csv'
  output_dir = 'data/splits'
  model_output_path = 'data/model.pkl'

  df = download_dataset(dataset_url, output_path)

  processed_df  = preprocess_dataset(df)

  dict_data = train_test_split(df_processed, output_dir)

  train_model(data_dict, model_output_path)

"""# **Kubeflow Pipeline Work Starts - Look at the file Pipeline_For_Model.py**"""







